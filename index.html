---
layout: default
tags: about
---
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script type="text/javascript">
  function readMore() {
    $('#readMore').hide();
    $('#more').show();
  }
  function readLess() {
    $('#readMore').show();
    $('#more').hide();
  }
</script>

<style>
      html * {
        font-size: 13px;
      }
      #thetable td:first-child {
        width: 20px;
    }

      /* a:link {
        color: blue;
        background-color: transparent;
        text-decoration: none;
      } */
</style>

<img src="images/Me.jpg" alt="Sri Siddarth C" width="240" style="float: right; padding: 0px; border-radius: 100%;" />
<div class="bio">
  <!-- <hr/> style="text-align:justify"-->
  <p>I am currently a Research Assistant in the <a href="https://lab1055.github.io/" class="uline">Machine Learning and Vision Group</a> at the Indian Institute of Technology Hyderabad (IITH), under the guidance of <a href="https://people.iith.ac.in/vineethnb/" class="uline"> Dr. Vineeth N Balasubramanian</a>. 
  My research revolves around <b><i>Explainable AI</i></b>, <b><i>Continual Learning</i></b>, and <b><i>Multi-Modal Learning</i></b>.

  <br><br>
  Previously, I collaborated with <a href="https://aero.iisc.ac.in/people/suresh-sundaram/" class="uline">Dr. Suresh Sundaram</a> at the Indian Institute of Science, extending our interactions from Nanyang Technological University, Singapore. I worked in the <a href="https://in.linkedin.com/company/artificial-intelligence-and-robotics-laboratory" class="uline">Artificial Intelligence and Robotics Laboratory</a> (AIRL) on Motion Planning for ground robotics and 3D reconstruction. I also helped develop an AI-enabled autonomous drone for surveillance using light-weight object detection models for real-time inference. 
  <br><br>
  I received my Bachelor's in Computer Science and Engineering from Vellore Institute of Technology (VIT)-Vellore, in 2022 (received the Research Excellence Award & Special Achieverâ€™s Award). I conducted my undergraduate thesis under the guidance of <a href="https://uk.linkedin.com/in/ashutoshnatraj" class="uline">Dr. Ashutosh Natraj</a> and <a href="https://research.vit.ac.in/researcher/vasantha-w-b" class="uline">Dr. Vasantha W B</a>. My research focused on <i>"Predictive and Prescriptive analysis for transmission power lines"</i> by leveraging <b>segmentation</b> and <b>object detection</b> models. This work led to the development of <i>VNautilus</i> and <i>VSense</i> applications in Vidrona's application portfolio, receiving the <b><i>ISGF award</i></b> from the <i>Ministry of Power</i>.
  At VIT,  I've had the opportunity to intern at <b>Hewlett Packard & Enterprises</b> (with <a href="https://in.linkedin.com/in/manikandadas" class="uline">Manikanda Das R</a>), <b>Samsung R&D Institute</b> (with <a href="https://www.linkedin.com/in/dr-satya-kumar-vankayala-91161b139/" class="uline">Dr. Satya Kumar Vankayala</a>), and Vidrona (with Dr.Ashutosh Natraj). Additionally, I conducted research at the VIT-Autonomous Research Center (ARC), contributing to lane detection models. In my final semester, I was honored to be a research exchange student (NTU-India Scholar) at Nanyang Technological University, Singapore, where I worked with <a href="https://dr.ntu.edu.sg/cris/rp/rp00965" class="uline">Dr. Xie Ming</a> on <i>Restricted Coulomb Energy</i> (RCE) Neural Networks for Semantic Segmentation in Autonomous Vehicles. 
  <br><br>
  After graduation, I collaborated with <b><i>OpenCV</i></b> for <b><i>Google Summer of Code</i></b> as an open-source developer and contributed to the OpenCV model zoo. My research interests lie in Continual Learning, ExplainableAI, and Multi-Modal Learning to improve generalization and overcome adversarial conditions in AI models. Recently, I have also developed an interest in <b><i>computer graphics</i></b>, and I am eager to expand my expertise into the realm of 3D computer vision.
  <br><br>
  During my free time I like to play the piano, play football (its not soccer), and paint pictures.

  <div class="container">
    <div class="row" style="text-align:center;">
      <div class="col-4">
        <div class="row">
          <div class="col-6">
            <a href="https://vit.ac.in/"><img src="images/VIT.png" style="max-height:150px;width:80%"></a>
          </div>
          <div class="col-6">
            <a href="https://www.gatech.edu/"><img src="images/gt.jpg" style="max-height:150px;width:100%"></a>
          </div>
        </div>
      </div>
      <div class="col-8">
        <div class="row" style="text-align:center;">
          <div class="col-3">
            <a href="https://www.hpe.com/in/en/home.html"><img src="images/HPE.png" style="width:80%;max-height:150px"></a>
          </div>
          <div class="col-3">
            <a href="https://uk.linkedin.com/company/vidrona-ltd"><img src="images/Vidrona.png" style="width:100%;max-height:175px"></a>
          </div>
          <div class="col-3">
            <a href="https://research.samsung.com/sri-b"><img src="images/SamsungResearch.png" style="width:80%;max-height:150px"></a>
          </div>
          <div class="col-3">
            <a href="https://summerofcode.withgoogle.com/archive/2022/organizations/opencv"><img src="images/GSOC.png" style="width:80%;max-height:150px"></a>
          </div>
        </div>
      </div>
    </div>
    <div class="row" style="text-align:center;">
      <div class="col-4">
        <div class="row">
          <div class="col-6">
            <div style="padding:10px">
              <span style="font-size: .6rem; font-weight:300;">2011-2015</span>
            </div>
          </div>
          <div class="col-6">
            <div style="padding:10px">
              <span style="font-size: .6rem; font-weight:300;">2017-2023</span>
            </div>
          </div>
        </div>
      </div>
      <div class="col-8">
        <div class="row" style="text-align:center;">
          <div class="col-3">
            <div style="padding:10px">
              <span style="font-size: .6rem; font-weight:300;">Summer '14, 2015-2016</span>
            </div>
          </div>
          <div class="col-3">
            <div style="padding:10px">
              <span style="font-size: .6rem; font-weight:300;">Summer 2018, 2019</span>
            </div>
          </div>
          <div class="col-3">
            <div style="padding:10px">
              <span style="font-size: .6rem; font-weight:300;">Summer 2021</span>
            </div>
          </div>
          <div class="col-3">
            <div style="padding:10px">
              <span style="font-size: .6rem; font-weight:300;">Summer 2022</span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  
</div>
<hr />
<div class="news">
  <h2>News</h2>
  <br />
  <ul>
    <li>
      <p>[Nov '23] Invited talk on <a href="https://www.youtube.com/watch?v=jCedCS1mTYg" class="uline">''Reliable Computer Vision''</a> at AWS Responsible AI.
      </p>
      </li>
    <li>
      <p>[Aug '23] Invited talks on <a href="https://www.youtube.com/watch?v=jCedCS1mTYg" class="uline">''Reliable Computer Vision''</a> at UC Berkeley and CMU.
      </p>
      </li>
    <li>
      <p>[Jan '23] Invited talk on ''Reliable Computer Vision'' at Machine Perception, Google Research.
      </p>
    </li>
    <li>
      <p>[Jun '22] Gave a tutorial on <a href="https://human-centeredai.github.io/" class="uline">Human-Centered AI for Computer Vision</a> at CVPR 2022.
      </p>
      </li>
    <li>
      <p>[May '22] Co-organizing <a href="https://l2id.github.io/l2id2022/" class="uline">Learning from Limited and Imperfect Data</a> at ECCV 2022.      
      </p>
    </li>
    <li>
      <p>[Oct '21] Recognized as an outstanding reviewer at <a href="https://nips.cc/Conferences/2021/ProgramCommittee"
        class="uline">NeurIPS 2021</a> and <a href="http://cvpr2021.thecvf.com/node/184" class="uline">CVPR 2021</a>.</p>
      </p>
    </li>
  </ul>
  <a id="readMore" class="uline" href="#" onclick="readMore();return false;">
    <div style='text-align: center;'>
      <h4>Read More</h4>
    </div>
  </a>
  <span id="more">
    <ul>
      <li>
        <p>[Jan '21] Head TA for <a href='https://sites.google.com/view/cs4476-sp21' class='uline'>Intro to Computer
            Vision</a>, Spring 2021.</p>
        </p>
      <li>
        <p>[May '19] Completed my Master's degree!</p>
      </li>
      <li>
        <p>[Mar '19] Awarded the College of Computing's <a
            href="https://www.cc.gatech.edu/content/annual-awards-and-honors-past-recipients" class="uline">MS Research
            award</a> (1 student annually).</p>
        </p>
      </li>      
  </span>
  </ul>
  <a id="readLess" class="uline" href="#" onclick="readLess();return false;">
    <div style='text-align: center;'>
      <h4>Read Less</h4>
    </div>
  </a>
</div>

<hr />

<div id="research">
  <h2><a name="research">Publications</a></h2>
  <br />

  <table width="100%" align="center" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
      <!-- <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            We're Not Using Videos Effectively: An Updated Video Domain Adaptation Baseline
          </h4>
          <p class="authors">
            Simar Kareer, Vivek Vijaykumar, Harsh Maheshwari, Judy Hoffman, Prithvijit Chattopadhyay, Viraj Prabhu
            <br />
          </p>
        </tr> -->
        <!-- <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/labeltranslation.jpg" style="max-height: 200px;">
          </div>
        </tr>
      </tr> -->
      <tr valign="middle" width="100%">
        <h4 style="font-weight: 500;">
          LANCE: Stress-testing Visual Models by Generating Language-guided Counterfactual Images
        </h4>
        <p>
          <a href="https://neurips.cc/"><span style="color:#9A2617; font-weight:500">NeurIPS 2023</span></a>
        </p>
        <p class="authors">
          Viraj Prabhu, Sriram Yenamandra, Prithvijit Chattopadhyay, Judy Hoffman
          <br />
        </p>
        <a class="btn btn-light" href="https://arxiv.org/abs/2305.19164" role="button">Paper</a>
        <a href="https://github.com/virajprabhu/LANCE" class="btn btn-light" role="button">Code</a>
          <a href="https://virajprabhu.github.io/lance-web/" class="btn btn-light" role="button">Project Page</a>
          
          <a href="https://ic.gatech.edu/external-news/stress-test-method-detects-when-object-recognition-models-are-using-shortcuts" class="btn btn-light" role="button">News</a>
      </tr>      
      <tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/LanceTeaserWeb.png" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>        
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Bridging the Sim2Real gap with CARE: Supervised Detection Adaptation with Conditional Alignment and Reweighting
          </h4>
          <p>
            <a href="https://jmlr.org/tmlr/index.html"><span style="color:#9A2617; font-weight:500">TMLR 2023</span></a>
          </p>
          <p class="authors">
            Viraj Prabhu, David Acuna, Yuan-Hong Liao, Rafid Mahmood, Marc T. Law, Judy Hoffman, Sanja Fidler, James Lucas
            <br />
          </p>
          <a href="https://openreview.net/forum?id=lAQQx7hlku" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/care.jpg" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Vision Tasks
          </h4>
          <p>
            <a href="https://neurips.cc/"><span style="color:#9A2617; font-weight:500">NeurIPS 2023 (Datasets & Benchmarks)</span></a>
          </p>
          <p class="authors">
            Micah Goldblum, Hossein Souri, Renkun Ni, Manli Shu, Viraj Prabhu, Gowthami Somepalli, Prithivijit Chattopadhyay, Adrien Bardes, Mark Ibrahim, Judy Hoffman, Rama Chellappa, Andrew Gordon Wilson, Tom Goldstein
            <br />
          </p>
          <a href="https://t.co/rmdIBNbDAx" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
          <a href="https://github.com/hsouri/Battle-of-the-Backbones" class="btn btn-light" role="button" aria-pressed="true">Code</a>
            <br />
          </tr>
          
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/backbone.png" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Translating Labels to Solve Annotation Mismatches Across Object Detection Datasets
          </h4>
          <p class="authors">
            Yuan-Hong Liao, David Acuna, Rafid Mahmood, James Lucas, Viraj Prabhu, Sanja Fidler
            <br />
          </p>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/labeltranslation.jpg" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            AUGCAL: Sim-to-Real Adaptation by Improving Uncertainty Calibration on Augmented Synthetic Images
          </h4>          
          <p>
            <a href="https://uncv2023.github.io/"><span style="color:#9A2617; font-weight:500">Uncertainty Quantification for Computer Vision, ICCV 2023</span></a>
         </p>          
          <p class="authors">
            Prithvijit Chattopadhyay, Bharat Goyal, Bogi Ecsedi, Viraj Prabhu, Judy Hoffman
            <br />
          </p>
          </tr>
          <tr width="100%">
            <div class="one" style="text-align:center;">
              <img src="images/augcal.jpg" style="max-height: 200px;">
            </div>
          </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            FACTS: First Amplify Correlations and Then Slice to Discover Bias
          </h4>
          <p>
            <a href="https://virajprabhu.com"><span style="color:#9A2617; font-weight:500">ICCV 2023</span></a>
         </p>
          <p class="authors">
            Sriram Yenamandra, Pratik Ramesh, Viraj Prabhu, Judy Hoffman
            <br />
          </p>    
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.pdf" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>      
          </tr>
          <tr width="100%">
            <div class="one" style="text-align:center;">
              <img src="images/facts.jpg" style="max-height: 200px;">
            </div>
          </tr>  
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            ICON<sup>2</sup>: Reliably Benchmarking Inequity in Detection by Identifying and Controlling for Confounders
          </h4>
          <p>
           <a href="https://trust-ai.github.io/SSAD2023/cfp"><span style="color:#9A2617; font-weight:500">Safe and Secure Autonomous Driving, CVPR 2023</span></a>
        </p>
          <p class="authors">
            Sruthi Sudhakar, Viraj Prabhu, Olga Russakovsky, Judy Hoffman
            <br />
          </p>
          <a href="https://arxiv.org/abs/2306.04482" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/icon2.jpeg" style="max-height: 200px;">
          </div>
        </tr>        
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency
          </h4>
          <p>
           <a href="https://neurips.cc/" ><span style="color:#9A2617; font-weight:500">NeurIPS 2022</span></a>
        </p>
          <p class="authors">
            Viraj Prabhu*, Sriram Yenamandra*, Aaditya Singh, Judy Hoffman (* = equal contribution)
            <br />            
          </p>
          <a href="https://openreview.net/pdf?id=OjS3nkNATOw" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
          <a href="https://www.cc.gatech.edu/news/new-system-image-object-recognition-modernizes-how-computers-learn-independently-and-transfer" class="btn btn-light" role="button" aria-pressed="true">News</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/approach_pacmac.jpg" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Can domain adaptation make object recognition work for everyone?
          </h4>
          <p>
           <a href="https://sites.google.com/view/l3d-ivu//"><span style="color:#9A2617; font-weight:500">Learning with Limited Labelled Data, CVPR 2022</span></a>
        </p>
          <p class="authors">
            Viraj Prabhu, Ramprasaath R. Selvaraju, Judy Hoffman, Nikhil Naik
            <br />
          </p>
          <a href="https://ieeexplore.ieee.org/document/9856652" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
        </tr>
      </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/teaser_ida.png" style="max-height: 200px;">
          </div>
        </tr>
        
    </tr>
    <hr>
      <tr>

        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            AUGCO: Augmentation Consistency-guided Self-training for Source-free Domain Adaptive Segmentation
          </h4>
          <p>
           <a href="https://computer-vision-in-the-wild.github.io/eccv-2022/"><span style="color:#9A2617; font-weight:500">Computer Vision in the Wild, ECCV 2022</span></a> (spotlight)
        </p>
          <p class="authors">
            Viraj Prabhu*, Shivam Khare*, Deeksha Kartik, Judy Hoffman (* = equal contribution)
            <br />            
          </p>
          <a href="https://arxiv.org/abs/2107.10140" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
            <a href="https://drive.google.com/file/d/1gTS-rfA-ArKCI4DyfL45IsjPF2ViV5uE/view" class="btn btn-light" role="button"
            aria-pressed="true">Video</a>
        </tr>
      </tr>
      <tr width="100%">
        <div class="one" style="text-align:center;">
          <img src="images/augco.png" style="max-height: 350px;">
        </div>
      </tr>
      <hr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            UDIS: Unsupervised Discovery of Bias in Deep Visual Recognition Models
          </h4>
          <p>
            <a href="http://www.bmvc2021.com/"><span style="color:#9A2617; font-weight:500">BMVC 2021</span></a>
          </p>
          <p class="authors">
            Arvind Krishnakumar, Viraj Prabhu, Sruthi Sudhakar, Judy Hoffman
            <br />
          </p>
          <a href="https://arxiv.org/abs/2110.15499" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
          <a href="https://github.com/akrishna77/bias-discovery" class="btn btn-light" role="button"
            aria-pressed="true">Code</a>
        </tr>
        <tr>
          <tr width="100%">
            <div class="one" style="text-align:center;">
              <img src="images/2021BMVC_UDIS.png" style="max-height: 150px;">
            </div>
          </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Mitigating Bias in Visual Transformers via Targeted Alignment
          </h4>
          <p>
            <a href="http://www.bmvc2021.com/"><span style="color:#9A2617; font-weight:500">BMVC 2021</span></a>
          </p>
          <p class="authors">
            Sruthi Sudhakar, Viraj Prabhu, Arvind Krishnakumar, Judy Hoffman
            <br />
          </p>
          <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0282.pdf"
            class="btn btn-light" role="button" aria-pressed="true">Paper</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/2021BMVCTadet.jpeg" style="max-height: 150px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Selective Entropy Optimization via Committee Consistency for Unsupervised Domain Adaptation
          </h4>
          <p>
            <a href="http://iccv2021.thecvf.com/"><span style="color:#9A2617; font-weight:500">ICCV 2021</span></a>
          </p>
          <p class="authors">
            Viraj Prabhu, Shivam Khare, Deeksha Kartik, Judy Hoffman
          </p>
          <a href="https://arxiv.org/abs/2012.11460" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
          <a href="https://virajprabhu.github.io/sentry-web/" class="btn btn-light" role="button"
            aria-pressed="true">Project Page</a>
          <a href="https://github.com/virajprabhu/SENTRY" class="btn btn-light" role="button"
            aria-pressed="true">Code</a>
          <a href="https://www.youtube.com/watch?v=sxxSGExAStY" class="btn btn-light" role="button"
            aria-pressed="true">Video</a>
          <a href="https://www.dropbox.com/s/53wwgz5wkwjlp4v/slides.pdf?dl=0" class="btn btn-light"
            role="button" aria-pressed="true">Slides</a>
          <a href="https://www.dropbox.com/s/htfqtui1i0qp3rz/sentry_poster.pdf?dl=0"
            class="btn btn-light" role="button" aria-pressed="true">Poster</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/teaser_sentry.png" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Active Domain Adaptation via Clustering Uncertainty-weighted Embeddings
          </h4>
          <p>
            <a href="http://iccv2021.thecvf.com/"><span style="color:#9A2617; font-weight:500">ICCV 2021</span></a>
          </p>
          <p class="authors">
            Viraj Prabhu, Arjun Chandrasekaran, Kate Saenko, Judy Hoffman
          </p>
          <!-- <button type="button" class="btn btn-outline-dark btn-sm">Paper</button> -->
          <a href="https://arxiv.org/abs/2010.08666" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
          <a href="https://virajprabhu.github.io/adaclue-web/" class="btn btn-light" role="button"
            aria-pressed="true">Project Page</a>
          <a href="https://github.com/virajprabhu/clue" class="btn btn-light" role="button"
            aria-pressed="true">Code</a>
          <a href="https://www.youtube.com/watch?v=VGSiORxS7BY" class="btn btn-light" role="button"
            aria-pressed="true">Video</a>
          <a href="https://www.dropbox.com/s/b85dpt8jzavl4rh/slides.pdf?dl=0" class="btn btn-light"
            role="button" aria-pressed="true">Slides</a>
          <a href="https://www.dropbox.com/s/gq2hellnq8nx2aq/clue_paper_poster.pdf?dl=0"
            class="btn btn-light" role="button" aria-pressed="true">Poster</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/teaser_toy.jpg" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Open Set Medical Diagnosis
          </h4>
          <p>
            <a href="https://ml4health.github.io/2019/"><span style="color:#9A2617; font-weight:500">Machine Learning for Health, NeurIPS 2019</span></a>
          </p>
          <p class="authors">
            Viraj Prabhu, Anitha Kannan, Geoffrey J. Tso, Namit Katariya, Manish Chablani, David Sontag, Xavier
            Amatriain
          </p>
          <a href="https://arxiv.org/abs/1910.02830" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/osd.png" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="middle" width="100%">
          <h4 style="font-weight: 500;">
            Few-shot Learning for Dermatological Disease Diagnosis
          </h4>
          <p>
            <a href="https://www.mlforhc.org/2019-conference"><span style="color:#9A2617; font-weight:500">MLHC 2019
                (spotlight)</span></a>, <a href="https://ml4health.github.io/2019/"><span
                style="color:#9A2617; font-weight:500">Machine Learning for Health, NeurIPS 2018</span></a>
          </p>
          <p class="authors">
            Viraj Prabhu, Anitha Kannan, Murali Ravuri, Manish Chablani, David Sontag, Xavier Amatriain
          </p>
          <a href="https://arxiv.org/abs/1811.03066" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/pcn.jpg" style="max-height: 150px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="bottom" width="100%">
          <h4 style="font-weight: 500;">
            Do Explanations make VQA Models more Predictable to a Human?
          </h4>
          <p>
            <a href="https://emnlp2018.org/"><span style="color:#9A2617; font-weight:500">EMNLP 2018</span></a>, <a
              href="http://chalearnlap.cvc.uab.es/workshop/22/description/"><span
                style="color:#9A2617; font-weight:500">Chalearn Looking at People, CVPR 2017</span></a>
          </p>
          <p class="authors">
            Arjun Chandrasekaran*, Viraj Prabhu*, Deshraj Yadav*, Prithvijit Chattopadhyay*, Devi Parikh (* = equal contribution)<br />          
          </p>
          <a href="https://www.aclweb.org/anthology/D18-1128.pdf" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/predictable.png" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="top" width="100%">
          <h4 style="font-weight: 500;">
            The Promise of Premise: Harnessing Question Premises in Visual Question Answering
          </h4>
          <p>
            <a href="https://www.aclweb.org/anthology/events/emnlp-2017/"><span
                style="color:#9A2617; font-weight:500">EMNLP 2017</span></a>
          </p>
          <p class="authors">
            Aroma Mahendru*, Viraj Prabhu*, Akrit Mohapatra*, Dhruv Batra, Stefan Lee (* = equal contribution)<br />            
          </p>
          <a href="https://arxiv.org/abs/1705.00601" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
          <a href="https://bitbucket.org/akrit_vt/premise_emnlp17" class="btn btn-light" role="button"
            aria-pressed="true">Code</a>
          <a href="https://virajprabhu.github.io/qpremise/dataset/" class="btn btn-light" role="button"
            aria-pressed="true">Dataset</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/premise.jpg" style="max-height: 200px;">
          </div>
        </tr>
      </tr>
      <hr>
      <tr>
        <tr valign="top" width="100%">
          <h4 style="font-weight: 500;">
            Evaluating Visual Conversational Agents via Cooperative Human-AI Games
          </h4>
          <p>
            <a href="https://www.humancomputation.com/2017/"><span style="color:#9A2617; font-weight:500">HCOMP
                2017</span></a>
          </p>
          <p class="authors">
            Prithvijit Chattopadhyay*, Deshraj Yadav*, Viraj Prabhu, Arjun Chandrasekaran, Abhishek Das, Stefan
            Lee, Dhruv Batra, Devi Parikh (* = equal contribution)
          </p>
          <a href="https://arxiv.org/abs/1708.05122" class="btn btn-light" role="button"
            aria-pressed="true">Paper</a>
          <a href="https://github.com/GT-Vision-Lab/GuessWhich" class="btn btn-light" role="button"
            aria-pressed="true">Code</a>
        </tr>
        <tr width="100%">
          <div class="one" style="text-align:center;">
            <img src="images/hcomp.jpg" style="display:block;margin:auto;margin-top:-30px;max-height: 200px;">
          </div>
        </tr>
      </tr>
    </tbody>
  </table>
</div>

<hr>

<div id="projects">
  <h2>Projects</h2>
  <table width="100%" align="center" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
      <tr>
        <td valign="top" width="75%">
          <h4 style="font-weight: 500;">
            Fabrik: An Online Collaborative Neural Network Editor
          </h4>
          <p class="authors">
            Utsav Garg, Viraj Prabhu, Deshraj Yadav, Ram Ramrakhya, Harsh Agrawal, Dhruv Batra
          </p>
          <p class="authors">Lead mentor on Fabrik, an open-source web platform to collaboratively build, visualize, and
            design neural networks in the browser.</p>
          <a href="https://arxiv.org/abs/1810.11649" class="btn btn-light" role="button"
            aria-pressed="true">Report</a>
          <a href="https://github.com/Cloud-CV/Fabrik" class="btn btn-light" role="button"
            aria-pressed="true">Code</a>
        </td>
        <td width="25%">
          <div class="one" style="text-align:center;">
            <div class="two" id="jump_image" style="opacity: 0;"></div>
            <img src="images/fabrik.png" style="max-height: 150px;">
          </div>
        </td>
      </tr>
      <tr>
        <td valign="top" width="75%">
          <h4 style="font-weight: 500;">PyTorch implementation of Learning Cooperative
              Visual Dialog Agents with Deep Reinforcement Learning</h4>
          <p class="authors">
            Nirbhay Modhe, Viraj Prabhu, Michael Cogswell, Satwik Kottur, Abhishek Das, Stefan Lee, Devi Parikh,
            Dhruv Batra
          </p>
          <a href="https://github.com/batra-mlp-lab/visdial-rl" class="btn btn-light" role="button"
            aria-pressed="true">Code</a>
        </td>
        <td width="25%">
          <div class="one" style="text-align:center;">
            <div class="two" id="jump_image" style="opacity: 0;"></div>
            <img src="images/visdial_rl.jpg" style="max-height: 150px;">
          </div>
        </td>
      </tr>
      <tr>
      <td valign="top" width="75%">
        <h4 style="font-weight: 500;">Adobe Captivate Prime</h4>
        <p class="authors">During my time as a software developer at Adobe (Aug '15-'16), I was responsible for the <a
            href="http://www.adobe.com/products/captivateprime.html" class="uline">Captivate Prime</a> Android app
          through two release cycles. I developed features for offline content play-back, syncing, and UI.
        </p>
      </td>
      <td width="25%">
        <div class="one" style="text-align:center;">
          <div class="two" style="opacity: 0;"></div>
          <img src="images/cp.jpeg" style="max-height: 150px;">
          <!-- </a> -->
        </div>
      </td>
      </tr>
      <tr>
        <td valign="top" width="75%">
          <h4 style="font-weight: 500;">Automated camera calibration </h4>
          <p class="authors">Over a research internship at <a href="http://tonboimaging.com/" class="uline">Tonbo
              Imaging</a> (Spring '15), I designed and implemented an algorithm for automated camera calibration.
          </p>
          </p>
        </td>
        <td width="25%">
          <div class="one" style="text-align:center;">
            <div class="two" style="opacity: 0;"></div>
            <img src="images/tonbo.png" style="max-height: 150px;">
          </div>
        </td>
      </tr>
      <tr>
        <td valign="top" width="75%">
          <h4 style="font-weight: 500;">KeyframeCut</h4>
          <p class="authors">Developed KeyframeCut, a fast graphcut-based segmentation
            algorithm for real-time background substitution in video, which was tech-transferred to Adobe Presenter Video Express 11.</p>
          <a href="https://www.youtube.com/watch?v=wM9mpFxaOpM" class="btn btn-light" role="button"
            aria-pressed="true">Demo</a>
          <a href="http://blogs.adobe.com/captivate/2016/03/adobe-presenter-video-express-the-end-of-green-screen.html"
            class="btn btn-light" role="button" aria-pressed="true">Blog</a>
          </p>
        </td>
        <td width="25%">
          <div class="one" style="text-align:center;">
            <div class="two" style="opacity: 0;"></div>
            <img src="images/mgs.png" style="max-height: 150px;">
          </div>
        </td>
    </tr>
    </tbody>
  </table>
</div>
<hr>
